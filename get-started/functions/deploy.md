---
description: MLOps and deployment related functions in PyCaret
---

# Deploy

## predict\_model

This function generates the label using a trained model.  When `data` is None, it predicts label and score on the holdout set.&#x20;

### **Hold-out predictions**

```
# load dataset
from pycaret.datasets import get_data
diabetes = get_data('diabetes')

# init setup
from pycaret.classification import *
clf1 = setup(data = diabetes, target = 'Class variable')

# create a model
xgboost = create_model('xgboost')

# predict on hold-out
predict_model(xgboost)
```

![Output from predict\_model(xgboost)](<../../.gitbook/assets/image (122).png>)

### **Unseen data predictions**

```
# load dataset
from pycaret.datasets import get_data
diabetes = get_data('diabetes')

# init setup
from pycaret.classification import *
clf1 = setup(data = diabetes, target = 'Class variable')

# create a model
xgboost = create_model('xgboost')

# predict on new data
new_data = diabetes.copy()
new_data.drop('Class variable', axis = 1, inplace = True)
predict_model(xgboost, data = new_data)
```

![Output from predict\_model(xgboost, data=new\_data)](<../../.gitbook/assets/image (328).png>)

### Probability by class

{% hint style="info" %}
**NOTE:** This is only applicable for the [Classification](../modules.md) use-cases.&#x20;
{% endhint %}

```
# load dataset
from pycaret.datasets import get_data
diabetes = get_data('diabetes')

# init setup
from pycaret.classification import *
clf1 = setup(data = diabetes, target = 'Class variable')

# create a model
xgboost = create_model('xgboost')

# predict on new data
new_data = diabetes.copy()
new_data.drop('Class variable', axis = 1, inplace = True)
predict_model(xgboost, raw_score = True, data = new_data)
```

![Output from predict\_model(xgboost, raw\_score = True, data = new\_data)](<../../.gitbook/assets/image (525).png>)

### Setting probability threshold

{% hint style="info" %}
**NOTE:** This is only applicable for the [Classification](../modules.md) use-cases (binary only).
{% endhint %}

The threshold for converting predicted probability to the class labels. Unless this parameter is set, it will default to the value set during model creation. If that wasn’t set, the default will be 0.5 for all classifiers. Only applicable for binary classification.

```
# load dataset
from pycaret.datasets import get_data
diabetes = get_data('diabetes')

# init setup
from pycaret.classification import *
clf1 = setup(data = diabetes, target = 'Class variable')

# create a model
xgboost = create_model('xgboost')

# probability threshold 0.3
predict_model(xgboost, probability_threshold = 0.3)
```

![Output from predict\_model(xgboost, probability\_threshold = 0.3)](<../../.gitbook/assets/image (533).png>)

#### Comparison between different thresholds on the hold-out data

![probability threshold = 0.5 vs. probability threshold = 0.3](<../../.gitbook/assets/image (311).png>)

### Monitor data drift

An interactive drift report can be generated by using `drift_report` parameter.

```
# load dataset
from pycaret.datasets import get_data
diabetes = get_data('diabetes')

# init setup
from pycaret.classification import *
clf1 = setup(data = diabetes, target = 'Class variable')

# create a model
xgboost = create_model('xgboost')

# predict on new data
predict_model(xgboost, drift_report = True)
```

![Output from predict\_model(xgboost, drift\_report = True)](<../../.gitbook/assets/image (133).png>)

![Drift Report (1/N)](<../../.gitbook/assets/image (447).png>)

![Drift Report (2/N)](<../../.gitbook/assets/image (368).png>)

![Drift Report (3/N)](<../../.gitbook/assets/image (411).png>)

## finalize\_model

This function trains a given model on the entire dataset including the hold-out set.

```
# load dataset
from pycaret.datasets import get_data
diabetes = get_data('diabetes')

# init setup
from pycaret.classification import *
clf1 = setup(data = diabetes, target = 'Class variable')

# create a model
rf = create_model('rf')

# finalize a model
finalize_model(rf)
```

![Output from finalize\_model(rf)](<../../.gitbook/assets/image (511).png>)

This function doesn't change any parameter of the model. It only refits on the entire dataset including the hold-out set.

## deploy\_model

This function deploys the entire ML pipeline on the cloud.

```
# load dataset
from pycaret.datasets import get_data
diabetes = get_data('diabetes')

# init setup
from pycaret.classification import *
clf1 = setup(data = diabetes, target = 'Class variable')

# create a model
lr = create_model('lr')

# finalize a model
final_lr = finalize_model(lr)

# deploy a model
deploy_model(final_lr, model_name = 'lr_aws', platform = 'aws', authentication = { 'bucket'  : 'pycaret-test' })
```

![Output from deploy\_model(...)](<../../.gitbook/assets/image (274).png>)

### AWS

Before deploying a model to an AWS S3 (‘aws’), environment variables must be configured using the command-line interface. To configure AWS environment variables, type **aws configure** in your python command line. The following information is required which can be generated using the Identity and Access Management (IAM) portal of your amazon console account:

* AWS Access Key ID
* AWS Secret Key Access
* Default Region Name (can be seen under Global settings on your AWS console)
* Default output format (must be left blank)

### GCP

To deploy a model on Google Cloud Platform ('gcp'), the project must be created using the command-line or GCP console. Once the project is created, you must create a service account and download the service account key as a JSON file to set environment variables in your local environment.

Learn more about it: [https://cloud.google.com/docs/authentication/production](https://cloud.google.com/docs/authentication/production)

### Azure

To deploy a model on Microsoft Azure ('azure'), environment variables for the connection string must be set in your local environment. Go to settings of storage account on Azure portal to access the connection string required.

* AZURE\_STORAGE\_CONNECTION\_STRING (required as environment variable)

Learn more about it: [https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-python?toc=%2Fpython%2Fazure%2FTOC.json](https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-python?toc=%2Fpython%2Fazure%2FTOC.json)

## save\_model

This function saves the transformation pipeline and a trained model object into the current working directory as a pickle file for later use.

```
# load dataset
from pycaret.datasets import get_data
diabetes = get_data('diabetes')

# init setup
from pycaret.classification import *
clf1 = setup(data = diabetes, target = 'Class variable')

# create a model
dt = create_model('dt')

# save pipeline
save_model(dt, 'dt_pipeline')
```

![Output from save\_model(dt, 'dt\_pipeline')](<../../.gitbook/assets/image (497).png>)

## load\_model

This function loads a previously saved pipeline.

```
# load dataset
from pycaret.datasets import get_data
diabetes = get_data('diabetes')

# init setup
from pycaret.classification import *
clf1 = setup(data = diabetes, target = 'Class variable')

# create a model
dt = create_model('dt')

# save pipeline
save_model(dt, 'dt_pipeline')

# load pipeline
load_model('dt_pipeline')
```

![Output from load\_model('dt\_pipeline')](<../../.gitbook/assets/image (457).png>)

## save\_config

This function saves all the global variables to a pickle file, allowing to later resume without rerunning the setup function.

```
# load dataset
from pycaret.datasets import get_data
diabetes = get_data('diabetes')

# init setup
from pycaret.classification import *
clf1 = setup(data = diabetes, target = 'Class variable')

# save config
save_config('my_config')
```

## load\_config

This function loads global variables from a pickle file into the Python environment.

```
from pycaret.classification import load_config
load_config('my_config')
```

## convert\_model

This function transpiles the trained machine learning model's decision function in different programming languages such as Python, C, Java, Go, C#, etc. It is very useful if you want to deploy models into environments where you can't install your normal Python stack to support model inference.

```
# load dataset
from pycaret.datasets import get_data
juice = get_data('juice')

# init setup
from pycaret.classification import *
exp_name = setup(data = juice,  target = 'Purchase')

# train a model
lr = create_model('lr')

# convert a model
convert_model(lr, 'java')
```

![Output from convert\_model(lr, 'java')](<../../.gitbook/assets/image (391).png>)

#### Video:

{% embed url="https://www.youtube.com/watch?t=1s&v=xwQgfNC7808" %}

## create\_api

This function takes an input model and creates a POST API for inference. It only creates the API and doesn't run it automatically. To run the API, you must run the Python file using `!python`.

```
# load dataset
from pycaret.datasets import get_data
juice = get_data('juice')

# init setup
from pycaret.classification import *
exp_name = setup(data = juice,  target = 'Purchase')

# train a model
lr = create_model('lr')

# create api
create_api(lr, 'lr_api')

# run api
!python lr_api.py
```

![Output from create\_api(lr, 'lr\_api')](<../../.gitbook/assets/image (310) (1).png>)

Once you initialize API with the `!python` command. You can see the server on localhost:8000/docs.

![FastAPI server hosted on localhost](<../../.gitbook/assets/image (74).png>)

#### Video:

{% embed url="https://www.youtube.com/watch?t=3s&v=88M9c5Hc-k0" %}

## create\_docker

This function creates a `Dockerfile` and `requirements.txt` for productionalizing API end-point.

```
# load dataset
from pycaret.datasets import get_data
juice = get_data('juice')

# init setup
from pycaret.classification import *
exp_name = setup(data = juice,  target = 'Purchase')

# train a model
lr = create_model('lr')

# create api
create_api(lr, 'lr_api')

# create docker
create_docker('lr_api')
```

![Output from create\_docker('lr\_api')](<../../.gitbook/assets/image (154).png>)

You can see two files are created for you.&#x20;

![%load requirements.txt](<../../.gitbook/assets/image (68).png>)

![%load DockerFile](<../../.gitbook/assets/image (309).png>)

#### Video:

{% embed url="https://www.youtube.com/watch?t=1s&v=xMgwEJ57uxs" %}

## create\_app

This function creates a basic `gradio` app for inference. It will later be expanded for other app types such `Streamlit`.

```
# load dataset
from pycaret.datasets import get_data
juice = get_data('juice')

# init setup
from pycaret.classification import *
exp_name = setup(data = juice,  target = 'Purchase')

# train a model
lr = create_model('lr')

# create app
create_app(lr)
```

![Output from create\_app(lr)](<../../.gitbook/assets/image (518) (1).png>)

#### Video:

{% embed url="https://www.youtube.com/watch?v=4JyYhbW6eCA" %}

